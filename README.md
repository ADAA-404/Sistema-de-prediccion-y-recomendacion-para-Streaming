# Sistema de predicci√≥n y recomendaci√≥n de tipo Netflix üçø

Este proyecto presenta un proceso integral de ciencia de datos para un servicio de streaming ficticio, centr√°ndose en dos objetivos comerciales fundamentales: predecir la p√©rdida de usuarios y mejorar su participaci√≥n mediante un sistema personalizado de recomendaci√≥n de pel√≠culas. Demuestra la capacidad de gestionar todo el ciclo de vida de la ciencia de datos, desde la limpieza de datos y la ingenier√≠a de caracter√≠sticas hasta la implementaci√≥n de modelos y la explicabilidad. 

## Fuente de Datos üíæ

El proyecto utiliza un conjunto de datos sint√©ticos obtenidos publicamente de Kaggle. Los datos se dividen en varios archivos CSV, pueden ser descargados y consultados aqui

> https://www.kaggle.com/datasets/sayeeduddin/netflix-2025user-behavior-dataset-210k-records?resource=download

## Tecnologias usadas üêç
Este proyecto se desarroll√≥ utilizando un s√≥lido conjunto de bibliotecas y herramientas de Python para cubrir todo el ciclo de vida del script.  

-   Pandas y NumPy: para la limpieza, manipulaci√≥n y ingenier√≠a de caracter√≠sticas de los datos.
-   Scikit-learn: para la divisi√≥n de datos, la evaluaci√≥n de modelos y la implementaci√≥n del sistema de recomendaciones basado en KNN.
-   XGBoost: una biblioteca de refuerzo de gradientes de alto rendimiento utilizada para construir el modelo de predicci√≥n de abandono.
-   SHAP (SHapley Additive exPlanations): Una potente biblioteca para explicar los resultados de los modelos de aprendizaje autom√°tico, fundamental para comunicar informaci√≥n empresarial.
-   Matplotlib y Seaborn: para la visualizaci√≥n de datos, incluidos gr√°ficos estad√≠sticos y los resultados de SHAP.
-   Streamlit: para crear e implementar el panel web interactivo, que presenta los resultados del proyecto en un formato f√°cil de usar.
-   Joblib: para guardar y cargar de manera eficiente los modelos de aprendizaje autom√°tico entrenados, lo que agiliza la aplicaci√≥n.

## Consideraciones en Instalaci√≥n ‚öôÔ∏è

Para configurar y ejecutar este proyecto, se recomienda utilizar un entorno `conda`. Estas librerias te ayudar√°n a crear el entorno necesario:

bash
    ```
    pip install pandas numpy scikit-learn XGBoost seaborn matplotlib SHAP Streamlit Joblib
    ```  
    
Configuraci√≥n de Datos: Aseg√∫rate de que los archivos de datos de la base de datos (conseguidas por Kaggle) esten ubicados en la carpeta con la que trabajas dentro de la estructura del proyecto.  
Ejecuta el Script: Simplemente corre el script principal para garantizar el funcionamientos desde cero, o despliega el streamlit considerando que tengas los archivos adjuntados en el repositorio para que funcione con la versi√≥n base.

## Ejemplo de Uso üìé

El pipeline de La soluci√≥n es un proceso multif√°sico creado con Python (probado desde Jupyter Notebook) e implementado con Streamlit.

Ingenier√≠a de datos y creaci√≥n de caracter√≠sticas:
-   Consolidaci√≥n de datos: los tres archivos CSV se fusionaron en un √∫nico DataFrame unificado.  
-   Definici√≥n de abandono: se defini√≥ como un periodo de inactividad de 30, 60 o 90 d√≠as.  
-   M√©tricas de interacci√≥n: para cuantificar la interacci√≥n de los usuarios, entre ellas total_watch_duration, sessions_per_week y unique_genres_watched.  

![Compilacion del script para DataFrame](Images/Ing_datos.png)

Modelo de predicci√≥n de abandono:
-   Selecci√≥n del modelo: se eligi√≥ un clasificador XGBoost por su alto rendimiento y su capacidad para manejar datos estructurados.  
-   Rendimiento del modelo: el modelo alcanz√≥ una precisi√≥n de 0,82 y una alta recuperaci√≥n de 0,92 (se puede comprobar mediante mas procedimiento).   

![Compilacion del script para modelo de prediccion](Images/predict_model.png)

Explicabilidad del modelo con SHAP:
-   Idea clave: Se utiliz√≥ SHAP (SHapley Additive exPlanations) donde el an√°lisis revel√≥ que sessions_per_week y unique_genres_watched eran los dos factores m√°s importantes para predecir la p√©rdida de clientes.  

![Compilacion del script para el modelo shap](Images/Shap_model.png)

Sistema de recomendaci√≥n de pel√≠culas"
-   Metodolog√≠a: Se implement√≥ un enfoque de filtrado colaborativo utilizando K-Nearest Neighbors (KNN).    
-   Matriz usuario-elemento: La participaci√≥n de los usuarios se cuantific√≥ mediante una m√©trica de porcentaje de progreso, que se utiliz√≥ para construir una matriz usuario-elemento dispersa para el modelo KNN.  
-   Resultado: El sistema recomienda con √©xito pel√≠culas a los usuarios bas√°ndose en los h√°bitos de visualizaci√≥n de usuarios similares, lo que proporciona una experiencia m√°s personalizada.  

![Compilacion del script para recomendacion fianl](Images/Recco_Syst.png)

Implementaci√≥n del panel de control:
-   Todo el proyecto se implementa como una aplicaci√≥n web interactiva utilizando Streamlit.

![Compilacion del script para desplegar streamlit](Images/Streamlit_deploy.png)


## Contribuciones üñ®Ô∏è

Si te interesa contribuir a este proyecto o usarlo independiente, considera:
-   Hacer un "fork" del repositorio.
-   Crear una nueva rama (`git checkout -b feature/su-caracteristica`).
-   Realizar tus cambios y "commiteelos" (`git commit -am 'Agrega nueva caracter√≠stica'`).
-   Subir los cambios a la rama (`git push origin feature/su-caracteristica`).
-   Abrir un "Pull Request".

## Licencia üìú

Este proyecto est√° bajo la Licencia MIT. Consulta el archivo LICENSE (si aplica) para m√°s detalles.


[English Version](README.en.md)

